{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "january_daily_tweets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMpEH7EBb4ytBWEz5ULGe5u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrf444/Coronavirus_Analysis/blob/master/january_daily_tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5Z0NfSaEmaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import gzip\n",
        "import json\n",
        "import pickle\n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATbFk3OBLB_I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "83c337de-7c2f-4ff9-d8d3-95636e0a30b2"
      },
      "source": [
        "drive.mount('/content/gdrive', force_remount = True)\n",
        "#clone repo\n",
        "#!git clone https://github.com/echen102/COVID-19-TweetIDs.git\n",
        "#move folder to \n",
        "#!mv '/content/COVID-19-TweetIDs' 'gdrive/My Drive/AdvPy/'\n",
        "os.chdir(\"gdrive/My Drive/AdvPy/COVID-19-TweetIDs\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQMpPrFbE755",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tweets_json(filename):\n",
        "  f = gzip.open(filename, 'rb')\n",
        "  response = f.read().decode('utf-8')\n",
        "  f.close()\n",
        "  return response.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_bn_WOVLwGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metadata_df(tweets, RT=False):\n",
        "  total_tweets = 0\n",
        "  latlong_tweets = 0\n",
        "\n",
        "  #create dataframe to store tweet metadata\n",
        "  df = pd.DataFrame(columns=['tweet_id',\n",
        "                                      'created_at',\n",
        "                                      'user_id',\n",
        "                                      'user_name',\n",
        "                                      'location',\n",
        "                                      'country',\n",
        "                                      'latitude',\n",
        "                                      'longitude',\n",
        "                                      'text'])\n",
        "\n",
        "  for i in range(len(tweets)):\n",
        "    try:\n",
        "      tweet = json.loads(tweets[i])\n",
        "    except:\n",
        "      #already formatted in JSON\n",
        "      if tweets[i] != '': #if tweet is not empty\n",
        "        tweet = tweets[i]\n",
        "\n",
        "    #NOTE: this line filters out retweets\n",
        "    if not RT: #if we don't want retweets\n",
        "      if 'RT' in tweet['full_text']: continue\n",
        "\n",
        "    try:    \n",
        "      #first, get location (city) and country depending on what info is available\n",
        "      if tweet['place'] != None:\n",
        "          location = tweet['place']['full_name']\n",
        "          country = tweet['place']['country_code']\n",
        "          \n",
        "      else:\n",
        "          location = tweet['user']['location'] #if actual city doesn't exist, get location provided by the user\n",
        "          country = np.nan\n",
        "          \n",
        "      #get latitude and longitude depending on whether an exact location or bounding box is provided\n",
        "      if tweet['coordinates'] != None: #exact location\n",
        "          longitude, latitude = tweet['coordinates']['coordinates']\n",
        "          \n",
        "      elif tweet['place'] != None: #bounding box --> take center point (average) of box\n",
        "          bounding_box = np.array(tweet['place']['bounding_box']['coordinates'][0])\n",
        "          longitude, latitude = np.mean(bounding_box, axis=0)\n",
        "          \n",
        "      else: #no location provided --> make nan\n",
        "          longitude = np.nan\n",
        "          latitude = np.nan\n",
        "\n",
        "      #append this tweet to the dataframe\n",
        "      df = df.append({'tweet_id':tweet['id'],\n",
        "                      'created_at':tweet['created_at'],\n",
        "                      'user_id':tweet['user']['id'],\n",
        "                      'user_name':tweet['user']['screen_name'],\n",
        "                      'location':location,\n",
        "                      'country':country,\n",
        "                      'latitude':latitude,\n",
        "                      'longitude':longitude,\n",
        "                      'text':tweet['full_text'],\n",
        "                    }, ignore_index=True)\n",
        "      \n",
        "    except:\n",
        "      continue\n",
        "\n",
        "  return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2lF9RUQPWTk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# '2020-01-21' <---- must be a string of this format\n",
        "def daily_tweets(day):\n",
        "  daily_df = pd.DataFrame(columns=['tweet_id',\n",
        "                                    'created_at',\n",
        "                                    'user_id',\n",
        "                                    'user_name',\n",
        "                                    'location',\n",
        "                                    'country',\n",
        "                                    'latitude',\n",
        "                                    'longitude',\n",
        "                                    'text'])\n",
        "  month_dir = day[:7]\n",
        "  hours = [\"%02d\" % n for n in range(24)]\n",
        "\n",
        "  for hour in hours:\n",
        "    filename = './'+month_dir+'/coronavirus-tweet-id-'+ \\\n",
        "                day+'-'+hour+'.jsonl.gz'\n",
        "    \n",
        "    if not os.path.exists(filename): #if file doesn't exist\n",
        "      continue\n",
        "    else:\n",
        "      print(\"\\rReading tweets for:\",day+'-'+hour, end='')\n",
        "      tweets = get_tweets_json(filename)\n",
        "      hourly_df = metadata_df(tweets) #RT = False\n",
        "      daily_df = pd.concat([daily_df,hourly_df])\n",
        "\n",
        "  return daily_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89H1L9gUXpsR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "outputId": "36b87d7f-9981-4ca2-faee-8038b74f8c52"
      },
      "source": [
        "day = '2020-01-23'\n",
        "daily_df = daily_tweets(day)\n",
        "daily_df"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading tweets for: 2020-01-23-23"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>created_at</th>\n",
              "      <th>user_id</th>\n",
              "      <th>user_name</th>\n",
              "      <th>location</th>\n",
              "      <th>country</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1220147193006432257</td>\n",
              "      <td>Thu Jan 23 00:52:14 +0000 2020</td>\n",
              "      <td>1050406362226847748</td>\n",
              "      <td>Jonatha43241211</td>\n",
              "      <td>North Carolina, USA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@DudeDudeologist @ThatShaneB @March_for_Life T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1220147242327330820</td>\n",
              "      <td>Thu Jan 23 00:52:26 +0000 2020</td>\n",
              "      <td>2723456510</td>\n",
              "      <td>TinfoilTricorn</td>\n",
              "      <td>Valley Forge, PA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@AnonsSynonymous @JackPosobiec CDC cannot be t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1220147392156262402</td>\n",
              "      <td>Thu Jan 23 00:53:02 +0000 2020</td>\n",
              "      <td>100903475</td>\n",
              "      <td>justintimkim</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CDC to screen at three US airports for signs o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1220147630900228102</td>\n",
              "      <td>Thu Jan 23 00:53:59 +0000 2020</td>\n",
              "      <td>1050406362226847748</td>\n",
              "      <td>Jonatha43241211</td>\n",
              "      <td>North Carolina, USA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@DudeDudeologist @ThatShaneB @March_for_Life 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1220147737112563713</td>\n",
              "      <td>Thu Jan 23 00:54:24 +0000 2020</td>\n",
              "      <td>1156624759637118976</td>\n",
              "      <td>HumanClimateGen</td>\n",
              "      <td>Pennsylvania, USA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>CDC details first U.S. case of novel virus spr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2028</th>\n",
              "      <td>1220481355819225088</td>\n",
              "      <td>Thu Jan 23 23:00:05 +0000 2020</td>\n",
              "      <td>11851702</td>\n",
              "      <td>dhughes</td>\n",
              "      <td>Charlottetown</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@Goatboy641 @juliaoftoronto Yes the 2019-nCov ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2029</th>\n",
              "      <td>1220481364270563328</td>\n",
              "      <td>Thu Jan 23 23:00:07 +0000 2020</td>\n",
              "      <td>30846824</td>\n",
              "      <td>TOICitiesNews</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>What is novel coronavirus (2019-nCoV)? https:/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2030</th>\n",
              "      <td>1220481548039880707</td>\n",
              "      <td>Thu Jan 23 23:00:51 +0000 2020</td>\n",
              "      <td>848638792206516224</td>\n",
              "      <td>PorterMedium</td>\n",
              "      <td>New York, USA</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Breaking: According to Public Health England, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2031</th>\n",
              "      <td>1220482683261857793</td>\n",
              "      <td>Thu Jan 23 23:05:21 +0000 2020</td>\n",
              "      <td>308148081</td>\n",
              "      <td>BubblesBurster</td>\n",
              "      <td>WW</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@realDonaldTrump What is crowdstrike?\\nWhy did...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2032</th>\n",
              "      <td>1220482683261857793</td>\n",
              "      <td>Thu Jan 23 23:05:21 +0000 2020</td>\n",
              "      <td>308148081</td>\n",
              "      <td>BubblesBurster</td>\n",
              "      <td>WW</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@realDonaldTrump What is crowdstrike?\\nWhy did...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>32145 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                 tweet_id  ...                                               text\n",
              "0     1220147193006432257  ...  @DudeDudeologist @ThatShaneB @March_for_Life T...\n",
              "1     1220147242327330820  ...  @AnonsSynonymous @JackPosobiec CDC cannot be t...\n",
              "2     1220147392156262402  ...  CDC to screen at three US airports for signs o...\n",
              "3     1220147630900228102  ...  @DudeDudeologist @ThatShaneB @March_for_Life 1...\n",
              "4     1220147737112563713  ...  CDC details first U.S. case of novel virus spr...\n",
              "...                   ...  ...                                                ...\n",
              "2028  1220481355819225088  ...  @Goatboy641 @juliaoftoronto Yes the 2019-nCov ...\n",
              "2029  1220481364270563328  ...  What is novel coronavirus (2019-nCoV)? https:/...\n",
              "2030  1220481548039880707  ...  Breaking: According to Public Health England, ...\n",
              "2031  1220482683261857793  ...  @realDonaldTrump What is crowdstrike?\\nWhy did...\n",
              "2032  1220482683261857793  ...  @realDonaldTrump What is crowdstrike?\\nWhy did...\n",
              "\n",
              "[32145 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1Nl4SDX692S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#year_month must be in format '2020-01'\n",
        "#folder is '2020-01-daily-dfs'\n",
        "def save_monthly_tweets(year_month,folder):\n",
        "  days = [year_month+'-%02d' % n for n in range(1,32)]\n",
        "  for day in days:\n",
        "    #if no tweet data for that day\n",
        "    if not [f for f in os.listdir('./'+year_month) if f.startswith(\"coronavirus-tweet-id-\"+day)]:\n",
        "      continue\n",
        "    else: #get the daily data frame and pickle it\n",
        "      daily_df = daily_tweets(day)\n",
        "      pickle_filename = './'+folder+'/'+day+'-tweets.pkl'\n",
        "      daily_df.to_pickle(pickle_filename)\n",
        "  return"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsSt84i6DENV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15f7e33d-3657-47f0-ceca-76e339b8f94c"
      },
      "source": [
        "save_monthly_tweets('2020-01','2020-01-daily-dfs')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading tweets for: 2020-01-25-08"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noepOfA-NN5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}