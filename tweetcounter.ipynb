{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from country_list import countries_for_language\n",
    "pd.set_option('display.max_rows',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.read_csv('GeopyCleanedTweets/geopy-cleaned-tweets.csv')\n",
    "masterd = dict(zip(master['unclean'],master['clean']))\n",
    "countrycodes = pd.read_csv('countrycodes.csv')\n",
    "countrycodes = dict(zip(countrycodes['Code'],countrycodes['Country']))\n",
    "countrycodes['NA'] = 'Namibia'\n",
    "del countrycodes[np.nan]\n",
    "countrycodes = {k.lower(): v.lower() for k,v in countrycodes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(columns=['date','country','count']).to_csv('testtweetcounts.csv',index=False)\n",
    "S3 = boto3.resource('s3')\n",
    "BUCKET = 'coronavirus-analysis'\n",
    "conn = S3.Bucket(BUCKET)\n",
    "fns = [object_summary.key for object_summary in conn.objects.filter(Prefix=\"TweetPickles/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_countries = dict(countries_for_language('en'))\n",
    "countries = [x.lower() for x in list(imported_countries.values())]\n",
    "def countrycheck(row):\n",
    "    if not any(country in row for country in countries):\n",
    "        return row\n",
    "    else:\n",
    "        for country in countries:\n",
    "            if country in row:\n",
    "                idx = row.find(country)\n",
    "                nextchar = row[idx:idx+len(country)+1]\n",
    "                if len(row)>idx+len(country)+1:\n",
    "                    continue\n",
    "                else:\n",
    "                    return country\n",
    "                    break\n",
    "\n",
    "states = [s.lower() for s in [\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\n",
    "          \"Connecticut\",\"Delaware\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\n",
    "          \"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\n",
    "          \"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\n",
    "          \"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\n",
    "          \"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\n",
    "          \"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\n",
    "          \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]]\n",
    "\n",
    "def statecheck(row):\n",
    "    for state in states:\n",
    "        if state in row:\n",
    "            return 'united states'\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleanng with 1/39\n",
      "13\n",
      "               tweet_id       location\n",
      "2   1219749757888925698  united states\n",
      "3   1219754028957085698         canada\n",
      "3   1219763184577531906         canada\n",
      "4   1219763518234189824  united states\n",
      "6   1219763961983270912  united states\n",
      "7   1219764042278944768  united states\n",
      "10  1219765213622231040  united states\n",
      "13  1219767394312257537  united states\n",
      "15  1219769725334573058  united states\n",
      "23  1219757614273310722  united states\n",
      "25  1219759656207294465  united states\n",
      "26  1219761426518200320  united states\n",
      "27  1219758887756345344  united states\n",
      "dirty\n",
      "11\n",
      "               tweet_id                  location\n",
      "0   1219753470116421636  united states of america\n",
      "0   1219762490193727488  united states of america\n",
      "1   1219762597097951234  united states of america\n",
      "2   1219763170006523904  united states of america\n",
      "8   1219764781197991942             united states\n",
      "9   1219764822897758208  united states of america\n",
      "17  1219770813215277057  united states of america\n",
      "18  1219761890794131456  united states of america\n",
      "19  1219757181903478791  united states of america\n",
      "22  1219762240573886464  united states of america\n",
      "28  1219761783746985984  united states of america\n",
      "final\n",
      "24\n",
      "               tweet_id       location\n",
      "2   1219749757888925698  united states\n",
      "3   1219754028957085698         canada\n",
      "3   1219763184577531906         canada\n",
      "4   1219763518234189824  united states\n",
      "6   1219763961983270912  united states\n",
      "7   1219764042278944768  united states\n",
      "10  1219765213622231040  united states\n",
      "13  1219767394312257537  united states\n",
      "15  1219769725334573058  united states\n",
      "23  1219757614273310722  united states\n",
      "25  1219759656207294465  united states\n",
      "26  1219761426518200320  united states\n",
      "27  1219758887756345344  united states\n",
      "0   1219753470116421636  united states\n",
      "0   1219762490193727488  united states\n",
      "1   1219762597097951234  united states\n",
      "2   1219763170006523904  united states\n",
      "8   1219764781197991942  united states\n",
      "9   1219764822897758208  united states\n",
      "17  1219770813215277057  united states\n",
      "18  1219761890794131456  united states\n",
      "19  1219757181903478791  united states\n",
      "22  1219762240573886464  united states\n",
      "28  1219761783746985984  united states\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/orion/venv/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "c = 1\n",
    "dropcols = ['created_at','user_id','user_name','latitude','longitude','text']\n",
    "for fn in fns:\n",
    "    print(f'Working with {c}/{len(fns)}',end='\\r')\n",
    "    date = fn.replace('TweetPickles/','').replace('-tweets.pkl','')\n",
    "    df = pickle.loads(S3.Bucket(BUCKET).Object(fn).get()['Body'].read()).drop(columns=dropcols).fillna('')\n",
    "    df['location'] = df['location'].str.strip()\n",
    "    df['country'] = df['country'].str.strip()\n",
    "    df = df[(df['location']!='')|(df['country']!='')].apply(lambda x: x.astype(str).str.lower())\n",
    "    df['country'] = df['country'].map(countrycodes).fillna('')\n",
    "    df['location'] = np.where(df['country']!='', df['country'], df['location'])\n",
    "    del df['country']\n",
    "    df['location'] = df['location'].apply(lambda row: statecheck(row))  \n",
    "    df['location'] = df['location'].apply(lambda row: countrycheck(row))    \n",
    "    counts = []\n",
    "    cleaned = df[df['location'].isin(countries)]\n",
    "    dirty = df[~df['location'].isin(countries)]\n",
    "    dirty['location'] = dirty['location'].map(masterd).fillna('')\n",
    "    dirty = dirty[dirty['location']!='']\n",
    "    final = cleaned.append(dirty)\n",
    "    final['location'] = final['location'].replace('united states of america','united states')\n",
    "#     dirty.to_pickle(f'./DirtyTweets/{date}-dirty-tweets.pkl')\n",
    "    items = list(map(list, dict(final['location'].value_counts()).items()))\n",
    "    dfcount = []\n",
    "    for i in items:\n",
    "        dated = [date]+[j for j in i]\n",
    "        dfcount.append(dated)\n",
    "    counts.append(dfcount)\n",
    "    counts = [x for y in counts for x in y]\n",
    "    countdf = pd.DataFrame(counts, columns=['date','country','count'])\n",
    "    countdf.to_csv('testtweetcounts.csv', mode='a', header=False)\n",
    "    c += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
