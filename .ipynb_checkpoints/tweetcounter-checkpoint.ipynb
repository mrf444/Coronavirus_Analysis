{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from country_list import countries_for_language\n",
    "pd.set_option('display.max_rows',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.read_csv('GeopyCleanedTweets/geopy-cleaned-tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterd = dict(zip(master['unclean'],master['clean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TweetPickles/2020-01-21-tweets.pkl', 'TweetPickles/2020-01-22-tweets.pkl', 'TweetPickles/2020-01-23-tweets.pkl']\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(columns=['date','country','count']).to_csv('testtweetcounts.csv',index=False)\n",
    "S3 = boto3.resource('s3')\n",
    "BUCKET = 'coronavirus-analysis'\n",
    "conn = S3.Bucket(BUCKET)\n",
    "fns = [object_summary.key for object_summary in conn.objects.filter(Prefix=\"TweetPickles/\")]\n",
    "print(fns[:3])\n",
    "\n",
    "imported_countries = dict(countries_for_language('en'))\n",
    "countries = [x.lower() for x in list(imported_countries.values())]\n",
    "def countrycheck(row):\n",
    "    if not any(country in row for country in countries):\n",
    "        return row\n",
    "    else:\n",
    "        for country in countries:\n",
    "            if country in row:\n",
    "                idx = row.find(country)\n",
    "                nextchar = row[idx:idx+len(country)+1]\n",
    "                if len(row)>idx+len(country)+1:\n",
    "                    continue\n",
    "                else:\n",
    "                    return country\n",
    "                    break\n",
    "\n",
    "states = [s.lower() for s in [\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\n",
    "          \"Connecticut\",\"Delaware\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\n",
    "          \"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\n",
    "          \"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\n",
    "          \"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\n",
    "          \"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\n",
    "          \"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\n",
    "          \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]]\n",
    "\n",
    "def statecheck(row):\n",
    "    for state in states:\n",
    "        if state in row:\n",
    "            return 'united states'\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 1/39\r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'countrycodes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-84b1bbc24c45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m|\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountrycodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'country'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'countrycodes' is not defined"
     ]
    }
   ],
   "source": [
    "c = 1\n",
    "dropcols = ['created_at','user_id','user_name','latitude','longitude','text']\n",
    "for fn in fns:\n",
    "    print(f'Working with {c}/{len(fns)}',end='\\r')\n",
    "    date = fn.replace('TweetPickles/','').replace('-tweets.pkl','')\n",
    "    df = pickle.loads(S3.Bucket(BUCKET).Object(fn).get()['Body'].read()).drop(columns=dropcols).fillna('')\n",
    "    df['location'] = df['location'].str.strip()\n",
    "    df['country'] = df['country'].str.strip()\n",
    "    df = df[(df['location']!='')|(df['country']!='')].apply(lambda x: x.astype(str).str.lower())\n",
    "    df['country'] = df['country'].map(countrycodes).fillna('')\n",
    "    df['location'] = np.where(df['country']!='', df['country'], df['location'])\n",
    "    del df['country']\n",
    "#     df['location'] = df['location'].apply(lambda row: statecheck(row))  \n",
    "#     df['location'] = df['location'].apply(lambda row: countrycheck(row))    \n",
    "#     counts = []\n",
    "#     cleaned = df[df['location'].isin(countries)]\n",
    "#     dirty = df[~df['location'].isin(countries)]\n",
    "#     dirty.to_pickle(f'./DirtyTweets/{date}-dirty-tweets.pkl')\n",
    "#     items = list(map(list, dict(cleaned['location'].value_counts()).items()))\n",
    "#     dfcount = []\n",
    "#     for i in items:\n",
    "#         dated = [date]+[j for j in i]\n",
    "#         dfcount.append(dated)\n",
    "#     counts.append(dfcount)\n",
    "#     counts = [x for y in counts for x in y]\n",
    "#     countdf = pd.DataFrame(counts, columns=['date','country','count'])\n",
    "#     countdf.to_csv('tweetcounts.csv', mode='a', header=False)\n",
    "#     c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
