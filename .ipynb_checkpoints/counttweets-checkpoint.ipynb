{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "import threading\n",
    "from geopy.geocoders import Nominatim\n",
    "from country_list import countries_for_language\n",
    "pd.set_option('display.max_rows',100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = pd.read_csv('GeopyCleanedTweets/geopy-cleaned-tweets.csv')\n",
    "masterd = dict(zip(master['unclean'],master['clean']))\n",
    "countrycodes = pd.read_csv('countrycodes.csv')\n",
    "countrycodes = dict(zip(countrycodes['Code'],countrycodes['Country']))\n",
    "countrycodes['NA'] = 'Namibia'\n",
    "del countrycodes[np.nan]\n",
    "countrycodes = {k.lower(): v.lower() for k,v in countrycodes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(columns=['date','country','count']).to_csv('ignore_tweetcounts.csv',index=False)\n",
    "S3 = boto3.resource('s3')\n",
    "BUCKET = 'coronavirus-analysis'\n",
    "conn = S3.Bucket(BUCKET)\n",
    "fns = [object_summary.key for object_summary in conn.objects.filter(Prefix=\"TweetPickles/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "imported_countries = dict(countries_for_language('en'))\n",
    "countries = [x.lower() for x in list(imported_countries.values())]\n",
    "def countrycheck(row):\n",
    "    if not any(country in row for country in countries):\n",
    "        return row\n",
    "    else:\n",
    "        for country in countries:\n",
    "            if country in row:\n",
    "                idx = row.find(country)\n",
    "                nextchar = row[idx:idx+len(country)+1]\n",
    "                if len(row)>idx+len(country)+1:\n",
    "                    continue\n",
    "                else:\n",
    "                    return country\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [s.lower() for s in [\"Alabama\",\"Alaska\",\"Arizona\",\"Arkansas\",\"California\",\"Colorado\",\n",
    "          \"Connecticut\",\"Delaware\",\"Florida\",\"Georgia\",\"Hawaii\",\"Idaho\",\"Illinois\",\n",
    "          \"Indiana\",\"Iowa\",\"Kansas\",\"Kentucky\",\"Louisiana\",\"Maine\",\"Maryland\",\n",
    "          \"Massachusetts\",\"Michigan\",\"Minnesota\",\"Mississippi\",\"Missouri\",\"Montana\",\n",
    "          \"Nebraska\",\"Nevada\",\"New Hampshire\",\"New Jersey\",\"New Mexico\",\"New York\",\n",
    "          \"North Carolina\",\"North Dakota\",\"Ohio\",\"Oklahoma\",\"Oregon\",\"Pennsylvania\",\n",
    "          \"Rhode Island\",\"South Carolina\",\"South Dakota\",\"Tennessee\",\"Texas\",\"Utah\",\n",
    "          \"Vermont\",\"Virginia\",\"Washington\",\"West Virginia\",\"Wisconsin\",\"Wyoming\"]]\n",
    "\n",
    "def statecheck(row):\n",
    "    for state in states:\n",
    "        if state in row:\n",
    "            return 'united states'\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df['location'] = df['location'].str.strip()\n",
    "    df['country'] = df['country'].str.strip()\n",
    "    df = df[(df['location']!='')|(df['country']!='')].apply(lambda x: x.astype(str).str.lower())\n",
    "    df['country'] = df['country'].map(countrycodes).fillna('')\n",
    "    df['location'] = np.where(df['country']!='', df['country'], df['location'])\n",
    "    del df['country']\n",
    "    df['location'] = df['location'].apply(lambda row: statecheck(row))  \n",
    "    df['location'] = df['location'].apply(lambda row: countrycheck(row))    \n",
    "    counts = []\n",
    "    cleaned = df[df['location'].isin(countries)]\n",
    "    dirty = df[~df['location'].isin(countries)]\n",
    "    dirty['location'] = dirty['location'].map(masterd).fillna('')\n",
    "    dirty = dirty[dirty['location']!='']\n",
    "    final = cleaned.append(dirty)\n",
    "    final['location'] = final['location'].replace('united states of america','united states')\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(df, countlist):\n",
    "    items = list(map(list, dict(df['location'].value_counts()).items()))\n",
    "    dfcount = []\n",
    "    for i in items:\n",
    "        dated = [date]+[j for j in i]\n",
    "        dfcount.append(dated)\n",
    "    countlist.append(dfcount)\n",
    "    counts = [x for y in countlist for x in y]\n",
    "    countdf = pd.DataFrame(counts, columns=['date','country','count'])\n",
    "    return countdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap(fn):\n",
    "    date = fn.replace('TweetPickles/','').replace('-tweets.pkl','')\n",
    "    df = pickle.loads(S3.Bucket(BUCKET).Object(fn).get()['Body'].read()).drop(columns=dropcols).fillna('')\n",
    "    counts = []\n",
    "    to_count = clean(df)\n",
    "    counted = count(to_count, counts)    \n",
    "    counted.to_csv('ignoretweetcounts.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process():\n",
    "    ts = time()\n",
    "    S3 = boto3.resource('s3')\n",
    "    BUCKET = 'coronavirus-analysis'\n",
    "    conn = S3.Bucket(BUCKET)\n",
    "    fns = [object_summary.key for object_summary in conn.objects.filter(Prefix=\"TweetPickles/\")]    \n",
    "\n",
    "    c = 1\n",
    "    for fn in fns:\n",
    "        print(f'Working with {c}/{len(fns)}',end='\\r')\n",
    "        wrap(fn)\n",
    "        c += 1\n",
    "    print('Cleaning and counting took {} s'.format(time() - ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threadprocess():\n",
    "    ts = time()\n",
    "    S3 = boto3.resource('s3')\n",
    "    BUCKET = 'coronavirus-analysis'\n",
    "    conn = S3.Bucket(BUCKET)\n",
    "    fns = [object_summary.key for object_summary in conn.objects.filter(Prefix=\"TweetPickles/\")]\n",
    "    \n",
    "    for fn in fns:\n",
    "        t = threading.Thread(target = wrap, args=(fn, )).start()\n",
    "        \n",
    "    print('Threading took {} s'.format(time() - ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threading took 0.46016502380371094 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/orion/venv/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "threadprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 1/39\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/orion/venv/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and counting took 765.2734231948853 s\n"
     ]
    }
   ],
   "source": [
    "process()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
